# Dockerized Hadoop, Spark, Hive, and Zeppelin
### Medium Article
https://medium.com/@bayuadiwibowo/deploying-a-big-data-ecosystem-dockerized-hadoop-spark-hive-and-zeppelin-654014069c82
### Cluster Operation
#### Start the Cluster

    hostname # docker compose up -d

#### Stop the Cluster

    hostname # docker compose down

### Access the UIs
Access all UIs using spawned firefox: http://localhost:5800/. All services uses default port, please find it from the respective documentation.